{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "setting up",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNBB/hZa6uOEdubhkycpvKk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elishatofunmi/Computer-Vision/blob/master/scripts/setting_up.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SejcJilo8-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6cb1f7d-a6e6-4bd5-abc9-2b3de13d79e4"
      },
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyEkuOVNpTit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Object_detection/')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9J8Rgv0qKsp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "82453d88-e3e3-463b-bcff-255c473cafdd"
      },
      "source": [
        "!pip install -U --pre tensorflow==\"2.2.0\"\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow==2.2.0 in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.30.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (2.2.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0) (3.12.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (49.1.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR8CjDFiq1Nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfXy5P8Hq6u7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e91192b7-1119-4488-bbd7-23f7b5f8de06"
      },
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install .\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/drive/My Drive/Object_detection/models/research\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.21)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.0.5)\n",
            "Requirement already satisfied: tf-models-official in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.2.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->object-detection==0.1) (49.1.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.5.6)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.1.0)\n",
            "Requirement already satisfied: mlperf-compliance==0.0.10 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.0.10)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.3.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.3.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.8.3)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.21.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.1.91)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.8.0)\n",
            "Requirement already satisfied: typing==3.7.4.1 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (3.7.4.1)\n",
            "Requirement already satisfied: oauth2client>=4.1.2 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (3.13)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (4.3.0.36)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.7.12)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.7)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (2020.6.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.0.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (19.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.22.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (3.12.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (0.3.2)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.2.1->tf-models-official->object-detection==0.1) (0.1.5)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (0.34.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.30.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (0.3.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (2.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (2.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (3.2.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.0.3)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.1.2->tf-models-official->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.1.2->tf-models-official->object-detection==0.1) (4.6)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.1.2->tf-models-official->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.1.2->tf-models-official->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.17.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets->tf-models-official->object-detection==0.1) (1.52.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.0.3->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow>=2.2.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1534294 sha256=cb3d49f69ce7582b52c16aa409319813f487ed02dd3d9282e28cb360b08ba296\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jioqjiol/wheels/74/bf/82/eec0d9b7ca4345af699d09569bdd5bdffa8790ce050f4ad71b\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "  Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed object-detection-0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjz6wdofgMob",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23355724-8e00-4113-b6ac-009cdf67fb3c"
      },
      "source": [
        "#commence temporary keras fix for exporting efficientDet - this will inevitably be fixed and removed from the notebook in the coming days\n",
        "%cat /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "#Roboflow: we are making a tiny change to the keras utils so we can export weights!\n",
            "\n",
            "# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n",
            "#\n",
            "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
            "# you may not use this file except in compliance with the License.\n",
            "# You may obtain a copy of the License at\n",
            "#\n",
            "#     http://www.apache.org/licenses/LICENSE-2.0\n",
            "#\n",
            "# Unless required by applicable law or agreed to in writing, software\n",
            "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
            "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
            "# See the License for the specific language governing permissions and\n",
            "# limitations under the License.\n",
            "# ==============================================================================\n",
            "\"\"\"TensorFlow-related utilities.\"\"\"\n",
            "from __future__ import absolute_import\n",
            "from __future__ import division\n",
            "from __future__ import print_function\n",
            "\n",
            "import copy\n",
            "import numpy as np\n",
            "import six\n",
            "\n",
            "from tensorflow.python.data.experimental.ops import cardinality\n",
            "from tensorflow.python.eager import context\n",
            "from tensorflow.python.framework import composite_tensor\n",
            "from tensorflow.python.framework import ops\n",
            "from tensorflow.python.framework import smart_cond as smart_module\n",
            "from tensorflow.python.framework import tensor_shape\n",
            "from tensorflow.python.framework import tensor_spec\n",
            "from tensorflow.python.framework import tensor_util\n",
            "from tensorflow.python.framework import type_spec\n",
            "from tensorflow.python.keras import backend as K\n",
            "from tensorflow.python.ops import control_flow_ops\n",
            "from tensorflow.python.ops import math_ops\n",
            "from tensorflow.python.ops import variables\n",
            "from tensorflow.python.util import nest\n",
            "from tensorflow.python.util import object_identity\n",
            "from tensorflow.python.util import tf_contextlib\n",
            "\n",
            "\n",
            "def smart_cond(pred, true_fn=None, false_fn=None, name=None):\n",
            "  \"\"\"Return either `true_fn()` if predicate `pred` is true else `false_fn()`.\n",
            "\n",
            "  If `pred` is a bool or has a constant value, we return either `true_fn()`\n",
            "  or `false_fn()`, otherwise we use `tf.cond` to dynamically route to both.\n",
            "\n",
            "  Arguments:\n",
            "    pred: A scalar determining whether to return the result of `true_fn` or\n",
            "      `false_fn`.\n",
            "    true_fn: The callable to be performed if pred is true.\n",
            "    false_fn: The callable to be performed if pred is false.\n",
            "    name: Optional name prefix when using `tf.cond`.\n",
            "\n",
            "  Returns:\n",
            "    Tensors returned by the call to either `true_fn` or `false_fn`.\n",
            "\n",
            "  Raises:\n",
            "    TypeError: If `true_fn` or `false_fn` is not callable.\n",
            "  \"\"\"\n",
            "  if isinstance(pred, variables.Variable):\n",
            "    return control_flow_ops.cond(\n",
            "        pred, true_fn=true_fn, false_fn=false_fn, name=name)\n",
            "  return smart_module.smart_cond(\n",
            "      pred, true_fn=true_fn, false_fn=false_fn, name=name)\n",
            "\n",
            "\n",
            "def constant_value(pred):\n",
            "  \"\"\"Return the bool value for `pred`, or None if `pred` had a dynamic value.\n",
            "\n",
            "  Arguments:\n",
            "    pred: A scalar, either a Python bool or a TensorFlow boolean variable\n",
            "      or tensor, or the Python integer 1 or 0.\n",
            "\n",
            "  Returns:\n",
            "    True or False if `pred` has a constant boolean value, None otherwise.\n",
            "\n",
            "  Raises:\n",
            "    TypeError: If `pred` is not a Variable, Tensor or bool, or Python\n",
            "      integer 1 or 0.\n",
            "  \"\"\"\n",
            "  # Allow integer booleans.\n",
            "  if isinstance(pred, int):\n",
            "    if pred == 1:\n",
            "      pred = True\n",
            "    elif pred == 0:\n",
            "      pred = False\n",
            "\n",
            "  if isinstance(pred, variables.Variable):\n",
            "    return None\n",
            "  return smart_module.smart_constant_value(pred)\n",
            "\n",
            "\n",
            "def is_tensor_or_tensor_list(v):\n",
            "  v = nest.flatten(v)\n",
            "  if v and isinstance(v[0], ops.Tensor):\n",
            "    return True\n",
            "  else:\n",
            "    return False\n",
            "\n",
            "\n",
            "def get_reachable_from_inputs(inputs, targets=None):\n",
            "  \"\"\"Returns the set of tensors/ops reachable from `inputs`.\n",
            "\n",
            "  Stops if all targets have been found (target is optional).\n",
            "\n",
            "  Only valid in Symbolic mode, not Eager mode.\n",
            "\n",
            "  Args:\n",
            "    inputs: List of tensors.\n",
            "    targets: List of tensors.\n",
            "\n",
            "  Returns:\n",
            "    A set of tensors reachable from the inputs (includes the inputs themselves).\n",
            "  \"\"\"\n",
            "  inputs = nest.flatten(inputs, expand_composites=True)\n",
            "  reachable = object_identity.ObjectIdentitySet(inputs)\n",
            "  if targets:\n",
            "    remaining_targets = object_identity.ObjectIdentitySet(nest.flatten(targets))\n",
            "  queue = inputs[:]\n",
            "\n",
            "  while queue:\n",
            "    x = queue.pop()\n",
            "    if isinstance(x, tuple(_user_convertible_tensor_types)):\n",
            "      # Can't find consumers of user-specific types.\n",
            "      continue\n",
            "\n",
            "    if isinstance(x, ops.Operation):\n",
            "      outputs = x.outputs[:] or []\n",
            "      outputs += x._control_outputs  # pylint: disable=protected-access\n",
            "    elif isinstance(x, variables.Variable):\n",
            "      try:\n",
            "        outputs = [x.op]\n",
            "      except AttributeError:\n",
            "        # Variables can be created in an Eager context.\n",
            "        outputs = []\n",
            "    elif tensor_util.is_tensor(x):\n",
            "      outputs = x.consumers()\n",
            "    else:\n",
            "      if not isinstance(x, str):\n",
            "        raise TypeError('Expected Operation, Variable, or Tensor, got ' + str(x))\n",
            "\n",
            "    for y in outputs:\n",
            "      if y not in reachable:\n",
            "        reachable.add(y)\n",
            "        if targets:\n",
            "          remaining_targets.discard(y)\n",
            "        queue.insert(0, y)\n",
            "\n",
            "    if targets and not remaining_targets:\n",
            "      return reachable\n",
            "\n",
            "  return reachable\n",
            "\n",
            "\n",
            "# This function needs access to private functions of `nest`.\n",
            "#  pylint: disable=protected-access\n",
            "def map_structure_with_atomic(is_atomic_fn, map_fn, nested):\n",
            "  \"\"\"Maps the atomic elements of a nested structure.\n",
            "\n",
            "  Arguments:\n",
            "    is_atomic_fn: A function that determines if an element of `nested` is\n",
            "      atomic.\n",
            "    map_fn: The function to apply to atomic elements of `nested`.\n",
            "    nested: A nested structure.\n",
            "\n",
            "  Returns:\n",
            "    The nested structure, with atomic elements mapped according to `map_fn`.\n",
            "\n",
            "  Raises:\n",
            "    ValueError: If an element that is neither atomic nor a sequence is\n",
            "      encountered.\n",
            "  \"\"\"\n",
            "  if is_atomic_fn(nested):\n",
            "    return map_fn(nested)\n",
            "\n",
            "  # Recursively convert.\n",
            "  if not nest.is_sequence(nested):\n",
            "    raise ValueError(\n",
            "        'Received non-atomic and non-sequence element: {}'.format(nested))\n",
            "  if nest._is_mapping(nested):\n",
            "    values = [nested[k] for k in nest._sorted(nested)]\n",
            "  else:\n",
            "    values = nested\n",
            "  mapped_values = [\n",
            "      map_structure_with_atomic(is_atomic_fn, map_fn, ele) for ele in values\n",
            "  ]\n",
            "  return nest._sequence_like(nested, mapped_values)\n",
            "\n",
            "\n",
            "#  pylint: enable=protected-access\n",
            "\n",
            "\n",
            "def convert_shapes(input_shape, to_tuples=True):\n",
            "  \"\"\"Converts nested shape representations to desired format.\n",
            "\n",
            "  Performs:\n",
            "\n",
            "  TensorShapes -> tuples if `to_tuples=True`.\n",
            "  tuples of int or None -> TensorShapes if `to_tuples=False`.\n",
            "\n",
            "  Valid objects to be converted are:\n",
            "  - TensorShapes\n",
            "  - tuples with elements of type int or None.\n",
            "  - ints\n",
            "  - None\n",
            "\n",
            "  Arguments:\n",
            "    input_shape: A nested structure of objects to be converted to TensorShapes.\n",
            "    to_tuples: If `True`, converts all TensorShape to tuples. Otherwise converts\n",
            "      all tuples representing shapes to TensorShapes.\n",
            "\n",
            "  Returns:\n",
            "    Nested structure of shapes in desired format.\n",
            "\n",
            "  Raises:\n",
            "    ValueError: when the input tensor shape can't be converted to tuples, eg\n",
            "      unknown tensor shape.\n",
            "  \"\"\"\n",
            "\n",
            "  def _is_shape_component(value):\n",
            "    return value is None or isinstance(value, (int, tensor_shape.Dimension))\n",
            "\n",
            "  def _is_atomic_shape(input_shape):\n",
            "    # Ex: TensorShape or (None, 10, 32) or 5 or `None`\n",
            "    if _is_shape_component(input_shape):\n",
            "      return True\n",
            "    if isinstance(input_shape, tensor_shape.TensorShape):\n",
            "      return True\n",
            "    if (isinstance(input_shape, (tuple, list)) and\n",
            "        all(_is_shape_component(ele) for ele in input_shape)):\n",
            "      return True\n",
            "    return False\n",
            "\n",
            "  def _convert_shape(input_shape):\n",
            "    input_shape = tensor_shape.TensorShape(input_shape)\n",
            "    if to_tuples:\n",
            "      input_shape = tuple(input_shape.as_list())\n",
            "    return input_shape\n",
            "\n",
            "  return map_structure_with_atomic(_is_atomic_shape, _convert_shape,\n",
            "                                   input_shape)\n",
            "\n",
            "\n",
            "class ListWrapper(object):\n",
            "  \"\"\"A wrapper for lists to be treated as elements for `nest`.\"\"\"\n",
            "\n",
            "  def __init__(self, list_to_wrap):\n",
            "    self._list = list_to_wrap\n",
            "\n",
            "  def as_list(self):\n",
            "    return self._list\n",
            "\n",
            "\n",
            "def convert_inner_node_data(nested, wrap=False):\n",
            "  \"\"\"Either wraps or unwraps innermost node data lists in `ListWrapper` objects.\n",
            "\n",
            "  Arguments:\n",
            "    nested: A nested data structure.\n",
            "    wrap: If `True`, wrap innermost lists in `ListWrapper` objects. If `False`,\n",
            "      unwraps `ListWrapper` objects into lists.\n",
            "\n",
            "  Returns:\n",
            "    Structure of same type as nested, with lists wrapped/unwrapped.\n",
            "  \"\"\"\n",
            "\n",
            "  def _is_serialized_node_data(nested):\n",
            "    # Node data can be of form `[layer_name, node_id, tensor_id]` or\n",
            "    # `[layer_name, node_id, tensor_id, kwargs]`.\n",
            "    if (isinstance(nested, list) and (len(nested) in [3, 4]) and\n",
            "        isinstance(nested[0], six.string_types)):\n",
            "      return True\n",
            "    return False\n",
            "\n",
            "  def _is_atomic_nested(nested):\n",
            "    \"\"\"Returns `True` if `nested` is a list representing node data.\"\"\"\n",
            "    if isinstance(nested, ListWrapper):\n",
            "      return True\n",
            "    if _is_serialized_node_data(nested):\n",
            "      return True\n",
            "    return not nest.is_sequence(nested)\n",
            "\n",
            "  def _convert_object_or_list(nested):\n",
            "    \"\"\"Convert b/t `ListWrapper` object and list representations.\"\"\"\n",
            "    if wrap:\n",
            "      if isinstance(nested, ListWrapper):\n",
            "        return nested\n",
            "      if _is_serialized_node_data(nested):\n",
            "        return ListWrapper(nested)\n",
            "      return nested\n",
            "    else:\n",
            "      if isinstance(nested, ListWrapper):\n",
            "        return nested.as_list()\n",
            "      return nested\n",
            "\n",
            "  return map_structure_with_atomic(_is_atomic_nested, _convert_object_or_list,\n",
            "                                   nested)\n",
            "\n",
            "\n",
            "def shape_type_conversion(fn):\n",
            "  \"\"\"Decorator that handles tuple/TensorShape conversion.\n",
            "\n",
            "  Used in `compute_output_shape` and `build`.\n",
            "\n",
            "  Arguments:\n",
            "    fn: function to wrap.\n",
            "\n",
            "  Returns:\n",
            "    Wrapped function.\n",
            "  \"\"\"\n",
            "\n",
            "  def wrapper(instance, input_shape):\n",
            "    # Pass shapes as tuples to `fn`\n",
            "    # This preserves compatibility with external Keras.\n",
            "    if input_shape is not None:\n",
            "      input_shape = convert_shapes(input_shape, to_tuples=True)\n",
            "    output_shape = fn(instance, input_shape)\n",
            "    # Return shapes from `fn` as TensorShapes.\n",
            "    if output_shape is not None:\n",
            "      output_shape = convert_shapes(output_shape, to_tuples=False)\n",
            "    return output_shape\n",
            "\n",
            "  return wrapper\n",
            "\n",
            "\n",
            "def are_all_symbolic_tensors(tensors):\n",
            "  return all(is_symbolic_tensor(tensor) for tensor in tensors)\n",
            "\n",
            "\n",
            "_user_convertible_tensor_types = set()\n",
            "\n",
            "\n",
            "def is_symbolic_tensor(tensor):\n",
            "  \"\"\"Returns whether a tensor is symbolic (from a TF graph) or an eager tensor.\n",
            "\n",
            "  A Variable can be seen as either: it is considered symbolic\n",
            "  when we are in a graph scope, and eager when we are in an eager scope.\n",
            "\n",
            "  Arguments:\n",
            "    tensor: A tensor instance to test.\n",
            "\n",
            "  Returns:\n",
            "    True for symbolic tensors, False for eager tensors.\n",
            "  \"\"\"\n",
            "  if isinstance(tensor, tuple(_user_convertible_tensor_types)):\n",
            "    tensor = ops.convert_to_tensor_or_composite(tensor)\n",
            "  if isinstance(tensor, variables.Variable):\n",
            "    # Variables that are output of a Keras Layer in Functional API mode\n",
            "    # should be considered symbolic.\n",
            "    # TODO(omalleyt): We need a better way to check this in order to\n",
            "    # enable `run_eagerly=True` for Models containing Layers that\n",
            "    # return Variables as outputs.\n",
            "    return (getattr(tensor, '_keras_history', False) or\n",
            "            not context.executing_eagerly())\n",
            "  if isinstance(tensor, composite_tensor.CompositeTensor):\n",
            "    component_tensors = nest.flatten(tensor, expand_composites=True)\n",
            "    return any(hasattr(t, 'graph') for t in component_tensors)\n",
            "  if isinstance(tensor, ops.Tensor):\n",
            "    return hasattr(tensor, 'graph')\n",
            "  return False\n",
            "\n",
            "\n",
            "def register_symbolic_tensor_type(cls):\n",
            "  \"\"\"Allows users to specify types regarded as symbolic `Tensor`s.\n",
            "\n",
            "  Used in conjunction with `tf.register_tensor_conversion_function`, calling\n",
            "  `tf.keras.utils.register_symbolic_tensor_type(cls)` allows non-`Tensor`\n",
            "  objects to be plumbed through Keras layers.\n",
            "\n",
            "  Example:\n",
            "\n",
            "  ```python\n",
            "  # One-time setup.\n",
            "  class Foo(object):\n",
            "    def __init__(self, input_):\n",
            "      self._input = input_\n",
            "    def value(self):\n",
            "      return tf.constant(42.)\n",
            "\n",
            "  tf.register_tensor_conversion_function(\n",
            "      Foo, lambda x, *args, **kwargs: x.value())\n",
            "\n",
            "  tf.keras.utils.register_symbolic_tensor_type(Foo)\n",
            "\n",
            "  # User-land.\n",
            "  layer = tf.keras.layers.Lambda(lambda input_: Foo(input_))\n",
            "  ```\n",
            "\n",
            "  Arguments:\n",
            "    cls: A `class` type which shall be regarded as a symbolic `Tensor`.\n",
            "  \"\"\"\n",
            "  global _user_convertible_tensor_types\n",
            "  _user_convertible_tensor_types.add(cls)\n",
            "\n",
            "\n",
            "def type_spec_from_value(value):\n",
            "  \"\"\"Grab type_spec without converting array-likes to tensors.\"\"\"\n",
            "  if isinstance(value, composite_tensor.CompositeTensor):\n",
            "    return value._type_spec  # pylint: disable=protected-access\n",
            "  # Get a TensorSpec for array-like data without\n",
            "  # converting the data to a Tensor\n",
            "  if hasattr(value, 'shape') and hasattr(value, 'dtype'):\n",
            "    return tensor_spec.TensorSpec(value.shape, value.dtype)\n",
            "  else:\n",
            "    return type_spec.type_spec_from_value(value)\n",
            "\n",
            "\n",
            "def is_tensor_or_variable(x):\n",
            "  return tensor_util.is_tensor(x) or isinstance(x, variables.Variable)\n",
            "\n",
            "\n",
            "def assert_no_legacy_layers(layers):\n",
            "  \"\"\"Prevent tf.layers.Layers from being used with Keras.\n",
            "\n",
            "  Certain legacy layers inherit from their keras analogs; however they are\n",
            "  not supported with keras and can lead to subtle and hard to diagnose bugs.\n",
            "\n",
            "  Args:\n",
            "    layers: A list of layers to check\n",
            "\n",
            "  Raises:\n",
            "    TypeError: If any elements of layers are tf.layers.Layers\n",
            "  \"\"\"\n",
            "\n",
            "  # isinstance check for tf.layers.Layer introduces a circular dependency.\n",
            "  legacy_layers = [l for l in layers if getattr(l, '_is_legacy_layer', None)]\n",
            "  if legacy_layers:\n",
            "    layer_str = '\\n'.join('  ' + str(l) for l in legacy_layers)\n",
            "    raise TypeError(\n",
            "        'The following are legacy tf.layers.Layers:\\n{}\\nTo use keras as a '\n",
            "        'framework (for instance using the Network, Model, or Sequential '\n",
            "        'classes), please use the tf.keras.layers implementation instead. '\n",
            "        '(Or, if writing custom layers, subclass from tf.keras.layers rather '\n",
            "        'than tf.layers)'.format(layer_str))\n",
            "\n",
            "\n",
            "@tf_contextlib.contextmanager\n",
            "def maybe_init_scope(layer):\n",
            "  \"\"\"Open an `init_scope` if in V2 mode and using the keras graph.\n",
            "\n",
            "  Arguments:\n",
            "    layer: The Layer/Model that is currently active.\n",
            "\n",
            "  Yields:\n",
            "    None\n",
            "  \"\"\"\n",
            "  # Don't open an init_scope in V1 mode or when using legacy tf.layers.\n",
            "  if (ops.executing_eagerly_outside_functions() and\n",
            "      getattr(layer, '_keras_style', True)):\n",
            "    with ops.init_scope():\n",
            "      yield\n",
            "  else:\n",
            "    yield\n",
            "\n",
            "\n",
            "@tf_contextlib.contextmanager\n",
            "def graph_context_for_symbolic_tensors(*args, **kwargs):\n",
            "  \"\"\"Returns graph context manager if any of the inputs is a symbolic tensor.\"\"\"\n",
            "  if any(is_symbolic_tensor(v) for v in list(args) + list(kwargs.values())):\n",
            "    with K.get_graph().as_default():\n",
            "      yield\n",
            "  else:\n",
            "    yield\n",
            "\n",
            "\n",
            "def dataset_is_infinite(dataset):\n",
            "  \"\"\"True if the passed dataset is infinite.\"\"\"\n",
            "  if ops.executing_eagerly_outside_functions():\n",
            "    return math_ops.equal(\n",
            "        cardinality.cardinality(dataset), cardinality.INFINITE)\n",
            "  else:\n",
            "    dataset_size = K.get_session().run(cardinality.cardinality(dataset))\n",
            "    return dataset_size == cardinality.INFINITE\n",
            "\n",
            "\n",
            "def get_tensor_spec(t, dynamic_batch=False, name=None):\n",
            "  \"\"\"Returns a `TensorSpec` given a single `Tensor` or `TensorSpec`.\"\"\"\n",
            "  if isinstance(t, type_spec.TypeSpec):\n",
            "    spec = t\n",
            "  elif isinstance(t, composite_tensor.CompositeTensor):\n",
            "    # TODO(b/148821952): Should these specs have a name attr?\n",
            "    spec = t._type_spec  # pylint: disable=protected-access\n",
            "  elif hasattr(t, 'shape') and hasattr(t, 'dtype'):\n",
            "    spec = tensor_spec.TensorSpec(shape=t.shape, dtype=t.dtype, name=name)\n",
            "  else:\n",
            "    return None  # Allow non-Tensors to pass through.\n",
            "\n",
            "  if not dynamic_batch:\n",
            "    return spec\n",
            "\n",
            "  dynamic_batch_spec = copy.deepcopy(spec)\n",
            "  # RaggedTensorSpec only has a private _shape.\n",
            "  shape = dynamic_batch_spec._shape.as_list()  # pylint: disable=protected-access\n",
            "  if shape:\n",
            "    shape[0] = None\n",
            "    dynamic_batch_spec._shape = tensor_shape.TensorShape(shape)  # pylint: disable=protected-access\n",
            "  return dynamic_batch_spec\n",
            "\n",
            "\n",
            "def to_numpy_or_python_type(tensors):\n",
            "  \"\"\"Converts a structure of `Tensor`s to `NumPy` arrays or Python scalar types.\n",
            "\n",
            "  For each tensor, it calls `tensor.numpy()`. If the result is a scalar value,\n",
            "  it converts it to a Python type, such as a float or int, by calling\n",
            "  `result.item()`.\n",
            "\n",
            "  Numpy scalars are converted, as Python types are often more convenient to deal\n",
            "  with. This is especially useful for bfloat16 Numpy scalars, which don't\n",
            "  support as many operations as other Numpy values.\n",
            "\n",
            "  Args:\n",
            "    tensors: A structure of tensors.\n",
            "\n",
            "  Returns:\n",
            "    `tensors`, but scalar tensors are converted to Python types and non-scalar\n",
            "    tensors are converted to Numpy arrays.\n",
            "  \"\"\"\n",
            "  def _to_single_numpy_or_python_type(t):\n",
            "    if isinstance(t, ops.Tensor):\n",
            "      x = t.numpy()\n",
            "      return x.item() if np.ndim(x) == 0 else x\n",
            "    return t  # Don't turn ragged or sparse tensors to NumPy.\n",
            "\n",
            "  return nest.map_structure(_to_single_numpy_or_python_type, tensors)"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bEwVDHWfw60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bfd37c5f-7d32-409a-c99b-1fa6971e791e"
      },
      "source": [
        "%%writefile /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\n",
        "\n",
        "\n",
        "#Roboflow: we are making a tiny change to the keras utils so we can export weights!\n",
        "\n",
        "# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"TensorFlow-related utilities.\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import copy\n",
        "import numpy as np\n",
        "import six\n",
        "\n",
        "from tensorflow.python.data.experimental.ops import cardinality\n",
        "from tensorflow.python.eager import context\n",
        "from tensorflow.python.framework import composite_tensor\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.framework import smart_cond as smart_module\n",
        "from tensorflow.python.framework import tensor_shape\n",
        "from tensorflow.python.framework import tensor_spec\n",
        "from tensorflow.python.framework import tensor_util\n",
        "from tensorflow.python.framework import type_spec\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.ops import control_flow_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops import variables\n",
        "from tensorflow.python.util import nest\n",
        "from tensorflow.python.util import object_identity\n",
        "from tensorflow.python.util import tf_contextlib\n",
        "\n",
        "\n",
        "def smart_cond(pred, true_fn=None, false_fn=None, name=None):\n",
        "  \"\"\"Return either `true_fn()` if predicate `pred` is true else `false_fn()`.\n",
        "\n",
        "  If `pred` is a bool or has a constant value, we return either `true_fn()`\n",
        "  or `false_fn()`, otherwise we use `tf.cond` to dynamically route to both.\n",
        "\n",
        "  Arguments:\n",
        "    pred: A scalar determining whether to return the result of `true_fn` or\n",
        "      `false_fn`.\n",
        "    true_fn: The callable to be performed if pred is true.\n",
        "    false_fn: The callable to be performed if pred is false.\n",
        "    name: Optional name prefix when using `tf.cond`.\n",
        "\n",
        "  Returns:\n",
        "    Tensors returned by the call to either `true_fn` or `false_fn`.\n",
        "\n",
        "  Raises:\n",
        "    TypeError: If `true_fn` or `false_fn` is not callable.\n",
        "  \"\"\"\n",
        "  if isinstance(pred, variables.Variable):\n",
        "    return control_flow_ops.cond(\n",
        "        pred, true_fn=true_fn, false_fn=false_fn, name=name)\n",
        "  return smart_module.smart_cond(\n",
        "      pred, true_fn=true_fn, false_fn=false_fn, name=name)\n",
        "\n",
        "\n",
        "def constant_value(pred):\n",
        "  \"\"\"Return the bool value for `pred`, or None if `pred` had a dynamic value.\n",
        "\n",
        "  Arguments:\n",
        "    pred: A scalar, either a Python bool or a TensorFlow boolean variable\n",
        "      or tensor, or the Python integer 1 or 0.\n",
        "\n",
        "  Returns:\n",
        "    True or False if `pred` has a constant boolean value, None otherwise.\n",
        "\n",
        "  Raises:\n",
        "    TypeError: If `pred` is not a Variable, Tensor or bool, or Python\n",
        "      integer 1 or 0.\n",
        "  \"\"\"\n",
        "  # Allow integer booleans.\n",
        "  if isinstance(pred, int):\n",
        "    if pred == 1:\n",
        "      pred = True\n",
        "    elif pred == 0:\n",
        "      pred = False\n",
        "\n",
        "  if isinstance(pred, variables.Variable):\n",
        "    return None\n",
        "  return smart_module.smart_constant_value(pred)\n",
        "\n",
        "\n",
        "def is_tensor_or_tensor_list(v):\n",
        "  v = nest.flatten(v)\n",
        "  if v and isinstance(v[0], ops.Tensor):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "\n",
        "def get_reachable_from_inputs(inputs, targets=None):\n",
        "  \"\"\"Returns the set of tensors/ops reachable from `inputs`.\n",
        "\n",
        "  Stops if all targets have been found (target is optional).\n",
        "\n",
        "  Only valid in Symbolic mode, not Eager mode.\n",
        "\n",
        "  Args:\n",
        "    inputs: List of tensors.\n",
        "    targets: List of tensors.\n",
        "\n",
        "  Returns:\n",
        "    A set of tensors reachable from the inputs (includes the inputs themselves).\n",
        "  \"\"\"\n",
        "  inputs = nest.flatten(inputs, expand_composites=True)\n",
        "  reachable = object_identity.ObjectIdentitySet(inputs)\n",
        "  if targets:\n",
        "    remaining_targets = object_identity.ObjectIdentitySet(nest.flatten(targets))\n",
        "  queue = inputs[:]\n",
        "\n",
        "  while queue:\n",
        "    x = queue.pop()\n",
        "    if isinstance(x, tuple(_user_convertible_tensor_types)):\n",
        "      # Can't find consumers of user-specific types.\n",
        "      continue\n",
        "\n",
        "    if isinstance(x, ops.Operation):\n",
        "      outputs = x.outputs[:] or []\n",
        "      outputs += x._control_outputs  # pylint: disable=protected-access\n",
        "    elif isinstance(x, variables.Variable):\n",
        "      try:\n",
        "        outputs = [x.op]\n",
        "      except AttributeError:\n",
        "        # Variables can be created in an Eager context.\n",
        "        outputs = []\n",
        "    elif tensor_util.is_tensor(x):\n",
        "      outputs = x.consumers()\n",
        "    else:\n",
        "      if not isinstance(x, str):\n",
        "        raise TypeError('Expected Operation, Variable, or Tensor, got ' + str(x))\n",
        "\n",
        "    for y in outputs:\n",
        "      if y not in reachable:\n",
        "        reachable.add(y)\n",
        "        if targets:\n",
        "          remaining_targets.discard(y)\n",
        "        queue.insert(0, y)\n",
        "\n",
        "    if targets and not remaining_targets:\n",
        "      return reachable\n",
        "\n",
        "  return reachable\n",
        "\n",
        "\n",
        "# This function needs access to private functions of `nest`.\n",
        "#  pylint: disable=protected-access\n",
        "def map_structure_with_atomic(is_atomic_fn, map_fn, nested):\n",
        "  \"\"\"Maps the atomic elements of a nested structure.\n",
        "\n",
        "  Arguments:\n",
        "    is_atomic_fn: A function that determines if an element of `nested` is\n",
        "      atomic.\n",
        "    map_fn: The function to apply to atomic elements of `nested`.\n",
        "    nested: A nested structure.\n",
        "\n",
        "  Returns:\n",
        "    The nested structure, with atomic elements mapped according to `map_fn`.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: If an element that is neither atomic nor a sequence is\n",
        "      encountered.\n",
        "  \"\"\"\n",
        "  if is_atomic_fn(nested):\n",
        "    return map_fn(nested)\n",
        "\n",
        "  # Recursively convert.\n",
        "  if not nest.is_sequence(nested):\n",
        "    raise ValueError(\n",
        "        'Received non-atomic and non-sequence element: {}'.format(nested))\n",
        "  if nest._is_mapping(nested):\n",
        "    values = [nested[k] for k in nest._sorted(nested)]\n",
        "  else:\n",
        "    values = nested\n",
        "  mapped_values = [\n",
        "      map_structure_with_atomic(is_atomic_fn, map_fn, ele) for ele in values\n",
        "  ]\n",
        "  return nest._sequence_like(nested, mapped_values)\n",
        "\n",
        "\n",
        "#  pylint: enable=protected-access\n",
        "\n",
        "\n",
        "def convert_shapes(input_shape, to_tuples=True):\n",
        "  \"\"\"Converts nested shape representations to desired format.\n",
        "\n",
        "  Performs:\n",
        "\n",
        "  TensorShapes -> tuples if `to_tuples=True`.\n",
        "  tuples of int or None -> TensorShapes if `to_tuples=False`.\n",
        "\n",
        "  Valid objects to be converted are:\n",
        "  - TensorShapes\n",
        "  - tuples with elements of type int or None.\n",
        "  - ints\n",
        "  - None\n",
        "\n",
        "  Arguments:\n",
        "    input_shape: A nested structure of objects to be converted to TensorShapes.\n",
        "    to_tuples: If `True`, converts all TensorShape to tuples. Otherwise converts\n",
        "      all tuples representing shapes to TensorShapes.\n",
        "\n",
        "  Returns:\n",
        "    Nested structure of shapes in desired format.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: when the input tensor shape can't be converted to tuples, eg\n",
        "      unknown tensor shape.\n",
        "  \"\"\"\n",
        "\n",
        "  def _is_shape_component(value):\n",
        "    return value is None or isinstance(value, (int, tensor_shape.Dimension))\n",
        "\n",
        "  def _is_atomic_shape(input_shape):\n",
        "    # Ex: TensorShape or (None, 10, 32) or 5 or `None`\n",
        "    if _is_shape_component(input_shape):\n",
        "      return True\n",
        "    if isinstance(input_shape, tensor_shape.TensorShape):\n",
        "      return True\n",
        "    if (isinstance(input_shape, (tuple, list)) and\n",
        "        all(_is_shape_component(ele) for ele in input_shape)):\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "  def _convert_shape(input_shape):\n",
        "    input_shape = tensor_shape.TensorShape(input_shape)\n",
        "    if to_tuples:\n",
        "      input_shape = tuple(input_shape.as_list())\n",
        "    return input_shape\n",
        "\n",
        "  return map_structure_with_atomic(_is_atomic_shape, _convert_shape,\n",
        "                                   input_shape)\n",
        "\n",
        "\n",
        "class ListWrapper(object):\n",
        "  \"\"\"A wrapper for lists to be treated as elements for `nest`.\"\"\"\n",
        "\n",
        "  def __init__(self, list_to_wrap):\n",
        "    self._list = list_to_wrap\n",
        "\n",
        "  def as_list(self):\n",
        "    return self._list\n",
        "\n",
        "\n",
        "def convert_inner_node_data(nested, wrap=False):\n",
        "  \"\"\"Either wraps or unwraps innermost node data lists in `ListWrapper` objects.\n",
        "\n",
        "  Arguments:\n",
        "    nested: A nested data structure.\n",
        "    wrap: If `True`, wrap innermost lists in `ListWrapper` objects. If `False`,\n",
        "      unwraps `ListWrapper` objects into lists.\n",
        "\n",
        "  Returns:\n",
        "    Structure of same type as nested, with lists wrapped/unwrapped.\n",
        "  \"\"\"\n",
        "\n",
        "  def _is_serialized_node_data(nested):\n",
        "    # Node data can be of form `[layer_name, node_id, tensor_id]` or\n",
        "    # `[layer_name, node_id, tensor_id, kwargs]`.\n",
        "    if (isinstance(nested, list) and (len(nested) in [3, 4]) and\n",
        "        isinstance(nested[0], six.string_types)):\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "  def _is_atomic_nested(nested):\n",
        "    \"\"\"Returns `True` if `nested` is a list representing node data.\"\"\"\n",
        "    if isinstance(nested, ListWrapper):\n",
        "      return True\n",
        "    if _is_serialized_node_data(nested):\n",
        "      return True\n",
        "    return not nest.is_sequence(nested)\n",
        "\n",
        "  def _convert_object_or_list(nested):\n",
        "    \"\"\"Convert b/t `ListWrapper` object and list representations.\"\"\"\n",
        "    if wrap:\n",
        "      if isinstance(nested, ListWrapper):\n",
        "        return nested\n",
        "      if _is_serialized_node_data(nested):\n",
        "        return ListWrapper(nested)\n",
        "      return nested\n",
        "    else:\n",
        "      if isinstance(nested, ListWrapper):\n",
        "        return nested.as_list()\n",
        "      return nested\n",
        "\n",
        "  return map_structure_with_atomic(_is_atomic_nested, _convert_object_or_list,\n",
        "                                   nested)\n",
        "\n",
        "\n",
        "def shape_type_conversion(fn):\n",
        "  \"\"\"Decorator that handles tuple/TensorShape conversion.\n",
        "\n",
        "  Used in `compute_output_shape` and `build`.\n",
        "\n",
        "  Arguments:\n",
        "    fn: function to wrap.\n",
        "\n",
        "  Returns:\n",
        "    Wrapped function.\n",
        "  \"\"\"\n",
        "\n",
        "  def wrapper(instance, input_shape):\n",
        "    # Pass shapes as tuples to `fn`\n",
        "    # This preserves compatibility with external Keras.\n",
        "    if input_shape is not None:\n",
        "      input_shape = convert_shapes(input_shape, to_tuples=True)\n",
        "    output_shape = fn(instance, input_shape)\n",
        "    # Return shapes from `fn` as TensorShapes.\n",
        "    if output_shape is not None:\n",
        "      output_shape = convert_shapes(output_shape, to_tuples=False)\n",
        "    return output_shape\n",
        "\n",
        "  return wrapper\n",
        "\n",
        "\n",
        "def are_all_symbolic_tensors(tensors):\n",
        "  return all(is_symbolic_tensor(tensor) for tensor in tensors)\n",
        "\n",
        "\n",
        "_user_convertible_tensor_types = set()\n",
        "\n",
        "\n",
        "def is_symbolic_tensor(tensor):\n",
        "  \"\"\"Returns whether a tensor is symbolic (from a TF graph) or an eager tensor.\n",
        "\n",
        "  A Variable can be seen as either: it is considered symbolic\n",
        "  when we are in a graph scope, and eager when we are in an eager scope.\n",
        "\n",
        "  Arguments:\n",
        "    tensor: A tensor instance to test.\n",
        "\n",
        "  Returns:\n",
        "    True for symbolic tensors, False for eager tensors.\n",
        "  \"\"\"\n",
        "  if isinstance(tensor, tuple(_user_convertible_tensor_types)):\n",
        "    tensor = ops.convert_to_tensor_or_composite(tensor)\n",
        "  if isinstance(tensor, variables.Variable):\n",
        "    # Variables that are output of a Keras Layer in Functional API mode\n",
        "    # should be considered symbolic.\n",
        "    # TODO(omalleyt): We need a better way to check this in order to\n",
        "    # enable `run_eagerly=True` for Models containing Layers that\n",
        "    # return Variables as outputs.\n",
        "    return (getattr(tensor, '_keras_history', False) or\n",
        "            not context.executing_eagerly())\n",
        "  if isinstance(tensor, composite_tensor.CompositeTensor):\n",
        "    component_tensors = nest.flatten(tensor, expand_composites=True)\n",
        "    return any(hasattr(t, 'graph') for t in component_tensors)\n",
        "  if isinstance(tensor, ops.Tensor):\n",
        "    return hasattr(tensor, 'graph')\n",
        "  return False\n",
        "\n",
        "\n",
        "def register_symbolic_tensor_type(cls):\n",
        "  \"\"\"Allows users to specify types regarded as symbolic `Tensor`s.\n",
        "\n",
        "  Used in conjunction with `tf.register_tensor_conversion_function`, calling\n",
        "  `tf.keras.utils.register_symbolic_tensor_type(cls)` allows non-`Tensor`\n",
        "  objects to be plumbed through Keras layers.\n",
        "\n",
        "  Example:\n",
        "\n",
        "  ```python\n",
        "  # One-time setup.\n",
        "  class Foo(object):\n",
        "    def __init__(self, input_):\n",
        "      self._input = input_\n",
        "    def value(self):\n",
        "      return tf.constant(42.)\n",
        "\n",
        "  tf.register_tensor_conversion_function(\n",
        "      Foo, lambda x, *args, **kwargs: x.value())\n",
        "\n",
        "  tf.keras.utils.register_symbolic_tensor_type(Foo)\n",
        "\n",
        "  # User-land.\n",
        "  layer = tf.keras.layers.Lambda(lambda input_: Foo(input_))\n",
        "  ```\n",
        "\n",
        "  Arguments:\n",
        "    cls: A `class` type which shall be regarded as a symbolic `Tensor`.\n",
        "  \"\"\"\n",
        "  global _user_convertible_tensor_types\n",
        "  _user_convertible_tensor_types.add(cls)\n",
        "\n",
        "\n",
        "def type_spec_from_value(value):\n",
        "  \"\"\"Grab type_spec without converting array-likes to tensors.\"\"\"\n",
        "  if isinstance(value, composite_tensor.CompositeTensor):\n",
        "    return value._type_spec  # pylint: disable=protected-access\n",
        "  # Get a TensorSpec for array-like data without\n",
        "  # converting the data to a Tensor\n",
        "  if hasattr(value, 'shape') and hasattr(value, 'dtype'):\n",
        "    return tensor_spec.TensorSpec(value.shape, value.dtype)\n",
        "  else:\n",
        "    return type_spec.type_spec_from_value(value)\n",
        "\n",
        "\n",
        "def is_tensor_or_variable(x):\n",
        "  return tensor_util.is_tensor(x) or isinstance(x, variables.Variable)\n",
        "\n",
        "\n",
        "def assert_no_legacy_layers(layers):\n",
        "  \"\"\"Prevent tf.layers.Layers from being used with Keras.\n",
        "\n",
        "  Certain legacy layers inherit from their keras analogs; however they are\n",
        "  not supported with keras and can lead to subtle and hard to diagnose bugs.\n",
        "\n",
        "  Args:\n",
        "    layers: A list of layers to check\n",
        "\n",
        "  Raises:\n",
        "    TypeError: If any elements of layers are tf.layers.Layers\n",
        "  \"\"\"\n",
        "\n",
        "  # isinstance check for tf.layers.Layer introduces a circular dependency.\n",
        "  legacy_layers = [l for l in layers if getattr(l, '_is_legacy_layer', None)]\n",
        "  if legacy_layers:\n",
        "    layer_str = '\\n'.join('  ' + str(l) for l in legacy_layers)\n",
        "    raise TypeError(\n",
        "        'The following are legacy tf.layers.Layers:\\n{}\\nTo use keras as a '\n",
        "        'framework (for instance using the Network, Model, or Sequential '\n",
        "        'classes), please use the tf.keras.layers implementation instead. '\n",
        "        '(Or, if writing custom layers, subclass from tf.keras.layers rather '\n",
        "        'than tf.layers)'.format(layer_str))\n",
        "\n",
        "\n",
        "@tf_contextlib.contextmanager\n",
        "def maybe_init_scope(layer):\n",
        "  \"\"\"Open an `init_scope` if in V2 mode and using the keras graph.\n",
        "\n",
        "  Arguments:\n",
        "    layer: The Layer/Model that is currently active.\n",
        "\n",
        "  Yields:\n",
        "    None\n",
        "  \"\"\"\n",
        "  # Don't open an init_scope in V1 mode or when using legacy tf.layers.\n",
        "  if (ops.executing_eagerly_outside_functions() and\n",
        "      getattr(layer, '_keras_style', True)):\n",
        "    with ops.init_scope():\n",
        "      yield\n",
        "  else:\n",
        "    yield\n",
        "\n",
        "\n",
        "@tf_contextlib.contextmanager\n",
        "def graph_context_for_symbolic_tensors(*args, **kwargs):\n",
        "  \"\"\"Returns graph context manager if any of the inputs is a symbolic tensor.\"\"\"\n",
        "  if any(is_symbolic_tensor(v) for v in list(args) + list(kwargs.values())):\n",
        "    with K.get_graph().as_default():\n",
        "      yield\n",
        "  else:\n",
        "    yield\n",
        "\n",
        "\n",
        "def dataset_is_infinite(dataset):\n",
        "  \"\"\"True if the passed dataset is infinite.\"\"\"\n",
        "  if ops.executing_eagerly_outside_functions():\n",
        "    return math_ops.equal(\n",
        "        cardinality.cardinality(dataset), cardinality.INFINITE)\n",
        "  else:\n",
        "    dataset_size = K.get_session().run(cardinality.cardinality(dataset))\n",
        "    return dataset_size == cardinality.INFINITE\n",
        "\n",
        "\n",
        "def get_tensor_spec(t, dynamic_batch=False, name=None):\n",
        "  \"\"\"Returns a `TensorSpec` given a single `Tensor` or `TensorSpec`.\"\"\"\n",
        "  if isinstance(t, type_spec.TypeSpec):\n",
        "    spec = t\n",
        "  elif isinstance(t, composite_tensor.CompositeTensor):\n",
        "    # TODO(b/148821952): Should these specs have a name attr?\n",
        "    spec = t._type_spec  # pylint: disable=protected-access\n",
        "  elif hasattr(t, 'shape') and hasattr(t, 'dtype'):\n",
        "    spec = tensor_spec.TensorSpec(shape=t.shape, dtype=t.dtype, name=name)\n",
        "  else:\n",
        "    return None  # Allow non-Tensors to pass through.\n",
        "\n",
        "  if not dynamic_batch:\n",
        "    return spec\n",
        "\n",
        "  dynamic_batch_spec = copy.deepcopy(spec)\n",
        "  # RaggedTensorSpec only has a private _shape.\n",
        "  shape = dynamic_batch_spec._shape.as_list()  # pylint: disable=protected-access\n",
        "  if shape:\n",
        "    shape[0] = None\n",
        "    dynamic_batch_spec._shape = tensor_shape.TensorShape(shape)  # pylint: disable=protected-access\n",
        "  return dynamic_batch_spec\n",
        "\n",
        "\n",
        "def to_numpy_or_python_type(tensors):\n",
        "  \"\"\"Converts a structure of `Tensor`s to `NumPy` arrays or Python scalar types.\n",
        "\n",
        "  For each tensor, it calls `tensor.numpy()`. If the result is a scalar value,\n",
        "  it converts it to a Python type, such as a float or int, by calling\n",
        "  `result.item()`.\n",
        "\n",
        "  Numpy scalars are converted, as Python types are often more convenient to deal\n",
        "  with. This is especially useful for bfloat16 Numpy scalars, which don't\n",
        "  support as many operations as other Numpy values.\n",
        "\n",
        "  Args:\n",
        "    tensors: A structure of tensors.\n",
        "\n",
        "  Returns:\n",
        "    `tensors`, but scalar tensors are converted to Python types and non-scalar\n",
        "    tensors are converted to Numpy arrays.\n",
        "  \"\"\"\n",
        "  def _to_single_numpy_or_python_type(t):\n",
        "    if isinstance(t, ops.Tensor):\n",
        "      x = t.numpy()\n",
        "      return x.item() if np.ndim(x) == 0 else x\n",
        "    return t  # Don't turn ragged or sparse tensors to NumPy.\n",
        "\n",
        "  return nest.map_structure(_to_single_numpy_or_python_type, tensors)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS8xAl_jrBYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import io\n",
        "import imageio\n",
        "import glob\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import colab_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZPldIIZfOoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8135880e-3f8a-4dc6-e669-0a71f790c02f"
      },
      "source": [
        "#run model builder test\n",
        "!python3 \"/content/drive/My Drive/Object_detection/models/research/object_detection/builders/model_builder_tf2_test.py\"\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-23 16:47:06.718382: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "Running tests under Python 3.6.9: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model\n",
            "2020-07-23 16:47:09.643901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-23 16:47:09.695561: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-07-23 16:47:09.695647: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0b5309a98faa): /proc/driver/nvidia/version does not exist\n",
            "2020-07-23 16:47:09.724793: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n",
            "2020-07-23 16:47:09.725127: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2a67100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-23 16:47:09.725175: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(True)\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(False)\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature(False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0723 16:47:20.566007 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0723 16:47:20.566270 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 64\n",
            "I0723 16:47:20.566363 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 3\n",
            "I0723 16:47:20.575412 140571445852032 efficientnet_model.py:146] round_filter input=32 output=32\n",
            "I0723 16:47:20.624732 140571445852032 efficientnet_model.py:146] round_filter input=32 output=32\n",
            "I0723 16:47:20.624938 140571445852032 efficientnet_model.py:146] round_filter input=16 output=16\n",
            "I0723 16:47:20.762318 140571445852032 efficientnet_model.py:146] round_filter input=16 output=16\n",
            "I0723 16:47:20.762531 140571445852032 efficientnet_model.py:146] round_filter input=24 output=24\n",
            "I0723 16:47:21.140290 140571445852032 efficientnet_model.py:146] round_filter input=24 output=24\n",
            "I0723 16:47:21.140497 140571445852032 efficientnet_model.py:146] round_filter input=40 output=40\n",
            "I0723 16:47:21.514407 140571445852032 efficientnet_model.py:146] round_filter input=40 output=40\n",
            "I0723 16:47:21.514623 140571445852032 efficientnet_model.py:146] round_filter input=80 output=80\n",
            "I0723 16:47:22.097995 140571445852032 efficientnet_model.py:146] round_filter input=80 output=80\n",
            "I0723 16:47:22.098227 140571445852032 efficientnet_model.py:146] round_filter input=112 output=112\n",
            "I0723 16:47:22.712365 140571445852032 efficientnet_model.py:146] round_filter input=112 output=112\n",
            "I0723 16:47:22.712569 140571445852032 efficientnet_model.py:146] round_filter input=192 output=192\n",
            "I0723 16:47:23.757725 140571445852032 efficientnet_model.py:146] round_filter input=192 output=192\n",
            "I0723 16:47:23.757934 140571445852032 efficientnet_model.py:146] round_filter input=320 output=320\n",
            "I0723 16:47:23.952711 140571445852032 efficientnet_model.py:146] round_filter input=1280 output=1280\n",
            "I0723 16:47:24.056561 140571445852032 efficientnet_model.py:459] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0723 16:47:24.161560 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0723 16:47:24.161791 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 88\n",
            "I0723 16:47:24.161893 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 4\n",
            "I0723 16:47:24.170195 140571445852032 efficientnet_model.py:146] round_filter input=32 output=32\n",
            "I0723 16:47:24.216014 140571445852032 efficientnet_model.py:146] round_filter input=32 output=32\n",
            "I0723 16:47:24.216246 140571445852032 efficientnet_model.py:146] round_filter input=16 output=16\n",
            "I0723 16:47:24.509363 140571445852032 efficientnet_model.py:146] round_filter input=16 output=16\n",
            "I0723 16:47:24.509567 140571445852032 efficientnet_model.py:146] round_filter input=24 output=24\n",
            "I0723 16:47:25.088003 140571445852032 efficientnet_model.py:146] round_filter input=24 output=24\n",
            "I0723 16:47:25.088234 140571445852032 efficientnet_model.py:146] round_filter input=40 output=40\n",
            "I0723 16:47:25.701254 140571445852032 efficientnet_model.py:146] round_filter input=40 output=40\n",
            "I0723 16:47:25.701480 140571445852032 efficientnet_model.py:146] round_filter input=80 output=80\n",
            "I0723 16:47:26.541353 140571445852032 efficientnet_model.py:146] round_filter input=80 output=80\n",
            "I0723 16:47:26.541561 140571445852032 efficientnet_model.py:146] round_filter input=112 output=112\n",
            "I0723 16:47:27.371138 140571445852032 efficientnet_model.py:146] round_filter input=112 output=112\n",
            "I0723 16:47:27.371360 140571445852032 efficientnet_model.py:146] round_filter input=192 output=192\n",
            "I0723 16:47:28.456636 140571445852032 efficientnet_model.py:146] round_filter input=192 output=192\n",
            "I0723 16:47:28.456860 140571445852032 efficientnet_model.py:146] round_filter input=320 output=320\n",
            "I0723 16:47:28.893864 140571445852032 efficientnet_model.py:146] round_filter input=1280 output=1280\n",
            "I0723 16:47:28.990112 140571445852032 efficientnet_model.py:459] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0723 16:47:29.344553 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0723 16:47:29.344781 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 112\n",
            "I0723 16:47:29.344880 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 5\n",
            "I0723 16:47:29.352730 140571445852032 efficientnet_model.py:146] round_filter input=32 output=32\n",
            "I0723 16:47:29.398253 140571445852032 efficientnet_model.py:146] round_filter input=32 output=32\n",
            "I0723 16:47:29.398460 140571445852032 efficientnet_model.py:146] round_filter input=16 output=16\n",
            "I0723 16:47:29.695023 140571445852032 efficientnet_model.py:146] round_filter input=16 output=16\n",
            "I0723 16:47:29.695256 140571445852032 efficientnet_model.py:146] round_filter input=24 output=24\n",
            "I0723 16:47:30.285815 140571445852032 efficientnet_model.py:146] round_filter input=24 output=24\n",
            "I0723 16:47:30.286024 140571445852032 efficientnet_model.py:146] round_filter input=40 output=48\n",
            "I0723 16:47:30.877530 140571445852032 efficientnet_model.py:146] round_filter input=40 output=48\n",
            "I0723 16:47:30.877741 140571445852032 efficientnet_model.py:146] round_filter input=80 output=88\n",
            "I0723 16:47:31.700957 140571445852032 efficientnet_model.py:146] round_filter input=80 output=88\n",
            "I0723 16:47:31.701189 140571445852032 efficientnet_model.py:146] round_filter input=112 output=120\n",
            "I0723 16:47:32.542263 140571445852032 efficientnet_model.py:146] round_filter input=112 output=120\n",
            "I0723 16:47:32.542474 140571445852032 efficientnet_model.py:146] round_filter input=192 output=208\n",
            "I0723 16:47:33.659761 140571445852032 efficientnet_model.py:146] round_filter input=192 output=208\n",
            "I0723 16:47:33.659972 140571445852032 efficientnet_model.py:146] round_filter input=320 output=352\n",
            "I0723 16:47:34.131573 140571445852032 efficientnet_model.py:146] round_filter input=1280 output=1408\n",
            "I0723 16:47:34.234237 140571445852032 efficientnet_model.py:459] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0723 16:47:34.359732 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0723 16:47:34.359958 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 160\n",
            "I0723 16:47:34.360075 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 6\n",
            "I0723 16:47:34.367932 140571445852032 efficientnet_model.py:146] round_filter input=32 output=40\n",
            "I0723 16:47:34.422725 140571445852032 efficientnet_model.py:146] round_filter input=32 output=40\n",
            "I0723 16:47:34.422942 140571445852032 efficientnet_model.py:146] round_filter input=16 output=24\n",
            "I0723 16:47:34.725267 140571445852032 efficientnet_model.py:146] round_filter input=16 output=24\n",
            "I0723 16:47:34.725482 140571445852032 efficientnet_model.py:146] round_filter input=24 output=32\n",
            "I0723 16:47:35.345026 140571445852032 efficientnet_model.py:146] round_filter input=24 output=32\n",
            "I0723 16:47:35.345278 140571445852032 efficientnet_model.py:146] round_filter input=40 output=48\n",
            "I0723 16:47:35.965158 140571445852032 efficientnet_model.py:146] round_filter input=40 output=48\n",
            "I0723 16:47:35.965364 140571445852032 efficientnet_model.py:146] round_filter input=80 output=96\n",
            "I0723 16:47:37.291579 140571445852032 efficientnet_model.py:146] round_filter input=80 output=96\n",
            "I0723 16:47:37.291792 140571445852032 efficientnet_model.py:146] round_filter input=112 output=136\n",
            "I0723 16:47:38.369324 140571445852032 efficientnet_model.py:146] round_filter input=112 output=136\n",
            "I0723 16:47:38.369535 140571445852032 efficientnet_model.py:146] round_filter input=192 output=232\n",
            "I0723 16:47:39.750406 140571445852032 efficientnet_model.py:146] round_filter input=192 output=232\n",
            "I0723 16:47:39.750618 140571445852032 efficientnet_model.py:146] round_filter input=320 output=384\n",
            "I0723 16:47:40.229987 140571445852032 efficientnet_model.py:146] round_filter input=1280 output=1536\n",
            "I0723 16:47:40.336400 140571445852032 efficientnet_model.py:459] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0723 16:47:40.474879 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0723 16:47:40.475122 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 224\n",
            "I0723 16:47:40.475223 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 7\n",
            "I0723 16:47:40.483203 140571445852032 efficientnet_model.py:146] round_filter input=32 output=48\n",
            "I0723 16:47:40.532387 140571445852032 efficientnet_model.py:146] round_filter input=32 output=48\n",
            "I0723 16:47:40.532594 140571445852032 efficientnet_model.py:146] round_filter input=16 output=24\n",
            "I0723 16:47:40.835640 140571445852032 efficientnet_model.py:146] round_filter input=16 output=24\n",
            "I0723 16:47:40.835849 140571445852032 efficientnet_model.py:146] round_filter input=24 output=32\n",
            "I0723 16:47:41.688423 140571445852032 efficientnet_model.py:146] round_filter input=24 output=32\n",
            "I0723 16:47:41.688647 140571445852032 efficientnet_model.py:146] round_filter input=40 output=56\n",
            "I0723 16:47:42.600757 140571445852032 efficientnet_model.py:146] round_filter input=40 output=56\n",
            "I0723 16:47:42.600981 140571445852032 efficientnet_model.py:146] round_filter input=80 output=112\n",
            "I0723 16:47:43.901718 140571445852032 efficientnet_model.py:146] round_filter input=80 output=112\n",
            "I0723 16:47:43.901934 140571445852032 efficientnet_model.py:146] round_filter input=112 output=160\n",
            "I0723 16:47:45.287379 140571445852032 efficientnet_model.py:146] round_filter input=112 output=160\n",
            "I0723 16:47:45.287597 140571445852032 efficientnet_model.py:146] round_filter input=192 output=272\n",
            "I0723 16:47:47.631250 140571445852032 efficientnet_model.py:146] round_filter input=192 output=272\n",
            "I0723 16:47:47.631458 140571445852032 efficientnet_model.py:146] round_filter input=320 output=448\n",
            "I0723 16:47:48.160610 140571445852032 efficientnet_model.py:146] round_filter input=1280 output=1792\n",
            "I0723 16:47:48.281378 140571445852032 efficientnet_model.py:459] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0723 16:47:48.435495 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0723 16:47:48.435723 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 288\n",
            "I0723 16:47:48.435818 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 7\n",
            "I0723 16:47:48.443638 140571445852032 efficientnet_model.py:146] round_filter input=32 output=48\n",
            "I0723 16:47:48.500456 140571445852032 efficientnet_model.py:146] round_filter input=32 output=48\n",
            "I0723 16:47:48.500668 140571445852032 efficientnet_model.py:146] round_filter input=16 output=24\n",
            "I0723 16:47:48.984228 140571445852032 efficientnet_model.py:146] round_filter input=16 output=24\n",
            "I0723 16:47:48.984448 140571445852032 efficientnet_model.py:146] round_filter input=24 output=40\n",
            "I0723 16:47:50.088265 140571445852032 efficientnet_model.py:146] round_filter input=24 output=40\n",
            "I0723 16:47:50.088473 140571445852032 efficientnet_model.py:146] round_filter input=40 output=64\n",
            "I0723 16:47:51.210663 140571445852032 efficientnet_model.py:146] round_filter input=40 output=64\n",
            "I0723 16:47:51.210877 140571445852032 efficientnet_model.py:146] round_filter input=80 output=128\n",
            "I0723 16:47:52.824144 140571445852032 efficientnet_model.py:146] round_filter input=80 output=128\n",
            "I0723 16:47:52.824364 140571445852032 efficientnet_model.py:146] round_filter input=112 output=176\n",
            "I0723 16:47:54.450255 140571445852032 efficientnet_model.py:146] round_filter input=112 output=176\n",
            "I0723 16:47:54.450464 140571445852032 efficientnet_model.py:146] round_filter input=192 output=304\n",
            "I0723 16:47:56.816017 140571445852032 efficientnet_model.py:146] round_filter input=192 output=304\n",
            "I0723 16:47:56.816257 140571445852032 efficientnet_model.py:146] round_filter input=320 output=512\n",
            "I0723 16:47:57.738356 140571445852032 efficientnet_model.py:146] round_filter input=1280 output=2048\n",
            "I0723 16:47:57.865724 140571445852032 efficientnet_model.py:459] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0723 16:47:58.467804 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0723 16:47:58.468061 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 384\n",
            "I0723 16:47:58.468169 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 8\n",
            "I0723 16:47:58.476108 140571445852032 efficientnet_model.py:146] round_filter input=32 output=56\n",
            "I0723 16:47:58.529881 140571445852032 efficientnet_model.py:146] round_filter input=32 output=56\n",
            "I0723 16:47:58.530114 140571445852032 efficientnet_model.py:146] round_filter input=16 output=32\n",
            "I0723 16:47:59.053138 140571445852032 efficientnet_model.py:146] round_filter input=16 output=32\n",
            "I0723 16:47:59.053348 140571445852032 efficientnet_model.py:146] round_filter input=24 output=40\n",
            "I0723 16:48:00.406757 140571445852032 efficientnet_model.py:146] round_filter input=24 output=40\n",
            "I0723 16:48:00.406969 140571445852032 efficientnet_model.py:146] round_filter input=40 output=72\n",
            "I0723 16:48:01.803555 140571445852032 efficientnet_model.py:146] round_filter input=40 output=72\n",
            "I0723 16:48:01.803763 140571445852032 efficientnet_model.py:146] round_filter input=80 output=144\n",
            "I0723 16:48:03.704985 140571445852032 efficientnet_model.py:146] round_filter input=80 output=144\n",
            "I0723 16:48:03.705274 140571445852032 efficientnet_model.py:146] round_filter input=112 output=200\n",
            "I0723 16:48:05.769870 140571445852032 efficientnet_model.py:146] round_filter input=112 output=200\n",
            "I0723 16:48:05.770113 140571445852032 efficientnet_model.py:146] round_filter input=192 output=344\n",
            "I0723 16:48:08.858891 140571445852032 efficientnet_model.py:146] round_filter input=192 output=344\n",
            "I0723 16:48:08.859119 140571445852032 efficientnet_model.py:146] round_filter input=320 output=576\n",
            "I0723 16:48:09.847380 140571445852032 efficientnet_model.py:146] round_filter input=1280 output=2304\n",
            "I0723 16:48:09.986083 140571445852032 efficientnet_model.py:459] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0723 16:48:10.181743 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0723 16:48:10.181977 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet BiFPN num filters: 384\n",
            "I0723 16:48:10.182088 140571445852032 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num iterations: 8\n",
            "I0723 16:48:10.189980 140571445852032 efficientnet_model.py:146] round_filter input=32 output=64\n",
            "I0723 16:48:10.242210 140571445852032 efficientnet_model.py:146] round_filter input=32 output=64\n",
            "I0723 16:48:10.242430 140571445852032 efficientnet_model.py:146] round_filter input=16 output=32\n",
            "I0723 16:48:10.960648 140571445852032 efficientnet_model.py:146] round_filter input=16 output=32\n",
            "I0723 16:48:10.960896 140571445852032 efficientnet_model.py:146] round_filter input=24 output=48\n",
            "I0723 16:48:12.639098 140571445852032 efficientnet_model.py:146] round_filter input=24 output=48\n",
            "I0723 16:48:12.639306 140571445852032 efficientnet_model.py:146] round_filter input=40 output=80\n",
            "I0723 16:48:14.854378 140571445852032 efficientnet_model.py:146] round_filter input=40 output=80\n",
            "I0723 16:48:14.854593 140571445852032 efficientnet_model.py:146] round_filter input=80 output=160\n",
            "I0723 16:48:17.402582 140571445852032 efficientnet_model.py:146] round_filter input=80 output=160\n",
            "I0723 16:48:17.402806 140571445852032 efficientnet_model.py:146] round_filter input=112 output=224\n",
            "I0723 16:48:20.074944 140571445852032 efficientnet_model.py:146] round_filter input=112 output=224\n",
            "I0723 16:48:20.075213 140571445852032 efficientnet_model.py:146] round_filter input=192 output=384\n",
            "I0723 16:48:24.042545 140571445852032 efficientnet_model.py:146] round_filter input=192 output=384\n",
            "I0723 16:48:24.042777 140571445852032 efficientnet_model.py:146] round_filter input=320 output=640\n",
            "I0723 16:48:25.582086 140571445852032 efficientnet_model.py:146] round_filter input=1280 output=2560\n",
            "I0723 16:48:25.737073 140571445852032 efficientnet_model.py:459] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 20 tests in 76.632s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipjIyQ6CrFmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: a file path.\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "def plot_detections(image_np,\n",
        "                    boxes,\n",
        "                    classes,\n",
        "                    scores,\n",
        "                    category_index,\n",
        "                    figsize=(12, 16),\n",
        "                    image_name=None):\n",
        "  \"\"\"Wrapper function to visualize detections.\n",
        "\n",
        "  Args:\n",
        "    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    boxes: a numpy array of shape [N, 4]\n",
        "    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n",
        "      and match the keys in the label map.\n",
        "    scores: a numpy array of shape [N] or None.  If scores=None, then\n",
        "      this function assumes that the boxes to be plotted are groundtruth\n",
        "      boxes and plot all boxes as black with no classes or scores.\n",
        "    category_index: a dict containing category dictionaries (each holding\n",
        "      category index `id` and category name `name`) keyed by category indices.\n",
        "    figsize: size for the figure.\n",
        "    image_name: a name for the image file.\n",
        "  \"\"\"\n",
        "  image_np_with_annotations = image_np.copy()\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_annotations,\n",
        "      boxes,\n",
        "      classes,\n",
        "      scores,\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      min_score_thresh=0.8)\n",
        "  if image_name:\n",
        "    plt.imsave(image_name, image_np_with_annotations)\n",
        "  else:\n",
        "    plt.imshow(image_np_with_annotations)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxnZ6igMntCB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39acea0c-9da4-4dc2-fd13-71c9703de2c8"
      },
      "source": [
        "cdir = os.getcwd()\n",
        "print(cdir)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWP_zRXxoSLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "5c9a1bb4-ca59-4cba-a17b-c5f7c9a61ed6"
      },
      "source": [
        "'/content/drive/My Drive/Object_detection/models/research/object_detection'\n",
        "os.chdir('./models/research/object_detection/checkpoint')\n",
        "os.listdir()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.ckpt.index',\n",
              " 'model.ckpt.meta',\n",
              " 'frozen_inference_graph.pb',\n",
              " 'model.ckpt.data-00000-of-00001',\n",
              " 'model.ckpt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RCAa6t4oglJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##change chosen model to deploy different models available in the TF2 object detection zoo\n",
        "MODELS_CONFIG = {\n",
        "    'SSD MobileNet': {\n",
        "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
        "        'batch_size': 5\n",
        "    }\n",
        "}\n",
        "\n",
        "#in this tutorial we implement the lightweight, smallest state of the art efficientdet model\n",
        "#if you want to scale up tot larger efficientdet models you will likely need more compute!\n",
        "chosen_model = 'SSD MobileNet'\n",
        "\n",
        "num_steps = 20 #The more steps, the longer the training. Increase if your loss function is still decreasing and validation metrics are increasing. \n",
        "num_eval_steps = 5 #Perform evaluation after so many steps\n",
        "\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
        "batch_size = MODELS_CONFIG[chosen_model]['batch_size'] #if you can fit a large batch in memory, it may speed up your training"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK4rEGZwqZUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "50a8eb31-3eb3-4f96-c676-34bbadc9e079"
      },
      "source": [
        "#download pretrained weights\n",
        "#%mkdir \"/content/drive/My Drive/Object_detection/models/research/deploy/\"\n",
        "%cd \"/content/drive/My Drive/Object_detection/models/research/deploy/\"\n",
        "import tarfile\n",
        "\n",
        "# \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\"\n",
        "\n",
        "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz'\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Object_detection/models/research/deploy\n",
            "--2020-07-23 16:48:31--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.70.128, 2607:f8b0:4001:c02::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.70.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46042990 (44M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz.5’\n",
            "\n",
            "ssd_mobilenet_v2_32 100%[===================>]  43.91M  71.4MB/s    in 0.6s    \n",
            "\n",
            "2020-07-23 16:48:31 (71.4 MB/s) - ‘ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz.5’ saved [46042990/46042990]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5i_uYg1DKEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d1f02a34-9f3a-47eb-838a-8c9e8a9f7a40"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Object_detection')\n",
        "os.getcwd()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Object_detection'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BliMKyBkwMZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n",
        "train_record_fname = './models/research/object_detection/datam/train.tfrecord'\n",
        "test_record_fname = './models/research/object_detection/datam/test.tfrecord'\n",
        "label_map_pbtxt_fname = './models/research/object_detection/datam/label_maps.pbtxt'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb8bBwfWu2N9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare\n",
        "pipeline_fname = './models/research/deploy/' + 'pipeline_file.config'\n",
        "fine_tune_checkpoint = './models/research/deploy/' + model_name + '/checkpoint/ckpt-0'\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "    \n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnx8GvKtrj1I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34503fd1-befb-4454-f962-70862480ab4a"
      },
      "source": [
        "num_classes"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCNs_JUuE4pd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e2374c7-03bc-4013-fa9f-23b9c1f46d0b"
      },
      "source": [
        "train_record_fname"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./models/research/object_detection/datam/train.tfrecord'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8_BwrlCFLzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpBJFHSyw8UV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #write custom configuration file by slotting our dataset, model checkpoint, and training parameters into the base pipeline file\n",
        "\n",
        "# import re\n",
        "\n",
        "# #%cd \"./Object_detection/models/research/deploy/\"\n",
        "# print('writing custom configuration file')\n",
        "\n",
        "# with open(pipeline_fname) as f:\n",
        "#     s = f.read()\n",
        "# with open('pipeline_file.config', 'w') as f:\n",
        "    \n",
        "#     # fine_tune_checkpoint\n",
        "#     s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "#                'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "#     # tfrecord files train and test.\n",
        "#     s = re.sub(\n",
        "#         '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "#     s = re.sub(\n",
        "#         '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "#     # label_map_path\n",
        "#     s = re.sub(\n",
        "#         'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "#     # Set training batch_size.\n",
        "#     s = re.sub('batch_size: [0-9]+',\n",
        "#                'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "#     # Set training steps, num_steps\n",
        "#     s = re.sub('num_steps: [0-9]+',\n",
        "#                'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "#     # Set number of classes num_classes.\n",
        "#     s = re.sub('num_classes: [0-9]+',\n",
        "#                'num_classes: {}'.format(num_classes), s)\n",
        "    \n",
        "#     #fine-tune checkpoint type\n",
        "#     s = re.sub(\n",
        "#         'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "        \n",
        "#     f.write(s)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1v8qyUpxPCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "09b4796c-e2f7-44dc-cf09-b7239c8abcb1"
      },
      "source": [
        "%cat './models/research/deploy/pipeline_file.config'"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 2\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: \"ssd_mobilenet_v2_keras\"\n",
            "      depth_multiplier: 1.0\n",
            "      min_depth: 16\n",
            "      conv_hyperparams {\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 3.9999998989515007e-05\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            mean: 0.0\n",
            "            stddev: 0.029999999329447746\n",
            "          }\n",
            "        }\n",
            "        activation: RELU_6\n",
            "        batch_norm {\n",
            "          decay: 0.9700000286102295\n",
            "          center: true\n",
            "          scale: true\n",
            "          epsilon: 0.0010000000474974513\n",
            "          train: true\n",
            "        }\n",
            "      }\n",
            "      override_base_feature_extractor_hyperparams: true\n",
            "    }\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "        use_matmul_gather: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        conv_hyperparams {\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 3.9999998989515007e-05\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            random_normal_initializer {\n",
            "              mean: 0.0\n",
            "              stddev: 0.009999999776482582\n",
            "            }\n",
            "          }\n",
            "          activation: RELU_6\n",
            "          batch_norm {\n",
            "            decay: 0.9700000286102295\n",
            "            center: true\n",
            "            scale: true\n",
            "            epsilon: 0.0010000000474974513\n",
            "            train: true\n",
            "          }\n",
            "        }\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.800000011920929\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        class_prediction_bias_init: -4.599999904632568\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.20000000298023224\n",
            "        max_scale: 0.949999988079071\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.33329999446868896\n",
            "      }\n",
            "    }\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 9.99999993922529e-09\n",
            "        iou_threshold: 0.6000000238418579\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "        use_static_shapes: false\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    loss {\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "          delta: 1.0\n",
            "        }\n",
            "      }\n",
            "      classification_loss {\n",
            "        weighted_sigmoid_focal {\n",
            "          gamma: 2.0\n",
            "          alpha: 0.75\n",
            "        }\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    encode_background_as_zeros: true\n",
            "    normalize_loc_loss_by_codesize: true\n",
            "    inplace_batchnorm_update: true\n",
            "    freeze_batchnorm: false\n",
            "  }\n",
            "}\n",
            "train_config {\n",
            "  batch_size: 20\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "  sync_replicas: true\n",
            "  optimizer {\n",
            "    momentum_optimizer {\n",
            "      learning_rate {\n",
            "        cosine_decay_learning_rate {\n",
            "          learning_rate_base: 0.800000011920929\n",
            "          total_steps: 50000\n",
            "          warmup_learning_rate: 0.13333000242710114\n",
            "          warmup_steps: 2000\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.8999999761581421\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/drive/My Drive/Object_detection/models/research/deploy/ssd_mobilenet_v2_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n",
            "  num_steps: 40\n",
            "  startup_delay_steps: 0.0\n",
            "  replicas_to_aggregate: 8\n",
            "  max_number_of_boxes: 100\n",
            "  unpad_groundtruth_tensors: false\n",
            "  fine_tune_checkpoint_type: \"detection\"\n",
            "  fine_tune_checkpoint_version: V2\n",
            "}\n",
            "train_input_reader {\n",
            "  label_map_path: \"/content/drive/My Drive/Object_detection/models/research/object_detection/datam/label_maps.pbtxt\"\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"./models/research/object_detection/datam/train.tfrecord\"\n",
            "  }\n",
            "}\n",
            "eval_config {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  use_moving_averages: false\n",
            "}\n",
            "eval_input_reader {\n",
            "  label_map_path: \"/content/drive/My Drive/Object_detection/models/research/object_detection/datam/label_maps.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_epochs: 1\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"./models/research/object_detection/datam/test.tfrecord\"\n",
            "  }\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOwCEk1Px9an",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline_file = \"./models/research/deploy/pipeline_file.config\"\n",
        "model_dir = \"./models/research/object_detection/training/\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5A7-EcO1TTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install tensorflow-gpu"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Boebn7z05Qq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        },
        "outputId": "3d522313-d834-4130-e579-a0db0dfbb6f8"
      },
      "source": [
        "!python \"./models/research/object_detection/model_main_tf2.py\" \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-23 16:48:37.230002: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-23 16:48:40.029753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-23 16:48:40.033311: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-07-23 16:48:40.033360: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0b5309a98faa): /proc/driver/nvidia/version does not exist\n",
            "2020-07-23 16:48:40.039557: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n",
            "2020-07-23 16:48:40.039803: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1aa4d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-23 16:48:40.039841: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "W0723 16:48:40.042226 139750974007168 cross_device_ops.py:1175] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "I0723 16:48:40.042493 139750974007168 mirrored_strategy.py:500] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 20\n",
            "I0723 16:48:40.049504 139750974007168 config_util.py:552] Maybe overwriting train_steps: 20\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0723 16:48:40.049734 139750974007168 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0723 16:48:40.159143 139750974007168 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "W0723 16:48:40.167075 139750974007168 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0723 16:48:40.204866 139750974007168 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0723 16:48:53.431931 139750974007168 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:79: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0723 16:49:00.217081 139750974007168 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0723 16:49:04.129487 139750974007168 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/inputs.py:259: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76mW81OVPYyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%reload_ext tensorboard"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCruRZV1ztSy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "31dfc7a6-a1b7-4144-d743-a6125c7d0d2c"
      },
      "source": [
        "!kill 496"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: kill: (496) - No such process\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHtKXDVN52bY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "outputId": "705e1000-bbe9-4e44-c9f9-8d46bb9ea0bf"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir './models/research/object_detection/training/'"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 496), started 3:56:32 ago. (Use '!kill 496' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = await google.colab.kernel.proxyPort(6006, {\"cache\": true});\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5rmIH5OJkzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "2829ba52-3757-4a31-d607-d187259bd2f0"
      },
      "source": [
        "#see where our model saved weights\n",
        "%ls './models/research/object_detection/training'"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint                  ckpt-2.index\n",
            "ckpt-1.data-00000-of-00001  ssd_mobilenet_v2_320x320_coco17_tpu-8.config\n",
            "ckpt-1.index                \u001b[0m\u001b[01;34mtrain\u001b[0m/\n",
            "ckpt-2.data-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v4vBgt4JuZM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "57e9f2b8-3bc3-48a1-af4f-051f308d7658"
      },
      "source": [
        "#run conversion script\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './models/research/deploy/fine_tuned_model'\n",
        "\n",
        "#place the model weights you would like to export here\n",
        "last_model_path = '/content/training/'\n",
        "print(last_model_path)\n",
        "!python './models/research/object_detection/exporter_main_v2.py' \\\n",
        "    --trained_checkpoint_dir {last_model_path} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {pipeline_file}"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/training/\n",
            "2020-07-23 16:49:37.694969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-23 16:49:45.947134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-23 16:49:45.998188: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-07-23 16:49:45.998298: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0b5309a98faa): /proc/driver/nvidia/version does not exist\n",
            "2020-07-23 16:49:46.059517: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz\n",
            "2020-07-23 16:49:46.059808: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3142d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-23 16:49:46.059855: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0723 16:49:55.069908 140031192520576 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0723 16:49:55.070390 140031192520576 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0723 16:49:55.070596 140031192520576 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0723 16:49:55.070770 140031192520576 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0723 16:49:55.070944 140031192520576 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0723 16:49:55.071125 140031192520576 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "Traceback (most recent call last):\n",
            "  File \"./models/research/object_detection/exporter_main_v2.py\", line 126, in <module>\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"./models/research/object_detection/exporter_main_v2.py\", line 122, in main\n",
            "    FLAGS.output_directory)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/object_detection/exporter_lib_v2.py\", line 172, in export_inference_graph\n",
            "    status.assert_existing_objects_matched()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\", line 877, in assert_existing_objects_matched\n",
            "    \"No checkpoint specified (save_path=None); nothing is being restored.\")\n",
            "AssertionError: No checkpoint specified (save_path=None); nothing is being restored.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWKTasqzK7Z0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d319fed8-8af6-4a7c-8978-1d79ec4c1cd1"
      },
      "source": [
        "%ls './models/research/deploy/fine_tuned_model/saved_model/'"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access './models/research/deploy/fine_tuned_model/saved_model/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKFLPo1VLAvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add images to a path and load"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRuczEifLA1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 31,
      "outputs": []
    }
  ]
}